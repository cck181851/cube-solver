# Rubik's Cube Solver: Installation and Reproduction Guide

## Overview

This repository implements, benchmarks, and extends two classical Rubik's Cube solvers (Thistlethwaite and Kociemba). The project now also contains ML-based difficulty prediction and data-collection tooling to support learning models that estimate cube difficulty and help prioritize test cases.

This README documents the new file layout, how to run the benchmark and ML workflows, and how to reproduce results.


---

## Highlights / New Features
- Complete benchmarking pipeline for **Thistlethwaite** & **Kociemba** solvers with detailed statistics and plots.
- ML integration: data collection, training-data generation, and an ML-based cube difficulty predictor (XGBoost / LightGBM compatible).
- Results and artifacts are saved to `benchmark_data/` and `ML_integration_data/` in the project root.
- Deterministic experiments through a fixed random seed for reproducibility.

---

## System Requirements

- **Operating System**: Windows 10/11, macOS 10.14+, or Linux (Ubuntu 18.04+)
- **Python**: Version **3.8** or higher
- **Memory**: Minimum **4GB RAM** (8GB recommended)
- **Storage**: **2GB** free space for tables and results
- **Processor**: x86-64 architecture

## Installation Steps

### 1. Clone the Repository

```bash
# clone the repository
git clone https://github.com/cck181851/rubiks-cube-benchmark.git
cd cube-solver
```

### 2.  Install Dependencies

```bash
pip install -r requirements.txt
```

**Core Dependencies:**

- `matplotlib>=3.5.0`
- `pandas>=1.3.0`
- `scikit-learn>=1.0.0`
- `xgboost>=1.5.0`
- `lightgbm>=3.3.0` 
- `seaborn>=0.11.0`
- `psutil>=5.9.0`

---

## Project Layout

```
<repo-root>/
├── src/
│ ├── benchmark/ # benchmark pipeline, plotting, categorization
│ ├── cube_solver/ # cube model, solvers, CLI
│ └── ML_integration/ # data collection, ML predictor, utilities
├── tables/ # precomputed pruning tables
├── benchmark_data/ # (generated by benchmark runs)
├── ML_integration_data/ # (generated by ML workflows)
├── requirements.txt
├── README.md # this file 
└── report.pdf
```

---

## Reproducing Benchmark Results

### Run Comprehensive Benchmark
Run all benchmark tests from the project root. The recommended/packaged entrypoint is the module runner so package imports work reliably:

```bash
python -m src.benchmark.benchmark
```

**This will:**
- Generates test cubes across difficulty levels (default set = 200 cubes, can be changed)
- Runs both solvers on each cube
- Collects timing, move counts, memory usage, nodes expanded
- Produces analysis plots and `benchmark_results.txt`
- Writes raw results to `benchmark_data/`
The number of cubes can be changed by editing the generator call in the main block of `benchmark.py`

### Running the ML workflows

There are two main ML-related scripts:
- Collect training data (generate labeled cases / features): 
  `python -m src.ML_integration.collect_training_data`
- Run the ML predictor (train / evaluate / predict):
  `python -m src.ML_integration.cube_ml_predictor`
Output and artifacts (models, CSVs) are written to `ML_integration_data/` by default. 

### Outputs & Where to look

- Benchmark statistics, plots and a human-readable benchmark_results.txt: benchmark_data/
- Raw logs, intermediate CSVs, and model files for ML: ML_integration_data/
- Precomputed pruning tables used by the solvers: tables/

---

## Reproducibility & Experimental Settings

- Deterministic seed: 3074742867 (the entire pipeline uses this fixed seed unless overridden).
- Timing: wall-clock measurements are used for runtime reporting.
- Memory tracking: tracemalloc is used to capture peak memory usage.
- System logging: system configuration is logged with each run for easier comparison.

Expected solver characteristics (for verification):
- Thistlethwaite: 20–35 moves, ~0.01–0.05 seconds average (machine dependent)
- Kociemba: 15–25 moves, ~0.05–0.3 seconds average (machine dependent)

---

## Customization / Tuning

To adjust experiment size, change the num_cubes parameter in src/benchmark/benchmark.py or expose it via CLI.
Modify visualization settings in src/benchmark/plot_comprehensive_analysis.py (palette, figure size, etc.). Example:
```
# palette change example
palette = sns.color_palette("Set2", n_colors=8)
# figure size example
fig, axes = plt.subplots(1, 2, figsize=(14, 6))
```

---

## Support 
For issues with reproduction:
- Check the system_info section in benchmark_results.txt
- Verify all table files are present in tables/ directory
- Ensure Python environment matches requirements

## Acknowledgement

The implementations of Kociemba and Thistlethwaite Algorithm are based on [cube-solver](https://github.com/itsdaveba/cube-solver)
by Dave Barragan, licensed under the MIT License.

The original code have been modified and extended to suit the requirements of this graduation project.

*Last updated: December 18, 2025 | Compatible with Python 3.8-3.11*
